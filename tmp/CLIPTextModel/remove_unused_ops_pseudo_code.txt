(Tensor(name=None, shape=77)) 
= reshape()(
Tensor(name=input, shape=1, 77), shape=[-1])

(Tensor(name=None, shape=77, 512)) 
= batch_gather()(
Tensor(name=token_embedding_weight, shape=49408, 512, data=(50593792 bytes)), Tensor(name=None, shape=77))

(IntVarTensor(1), IntVarTensor(77)) 
= size()(
Tensor(name=input, shape=1, 77))

(Tensor(name=None, shape=1, 77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[1, 77, -1])

(Tensor(name=None, shape=1, 77, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=1, 77, 512), Tensor(name=positional_embedding, shape=77, 512, data=(78848 bytes)))

(Tensor(name=None, shape=77, 1, 512)) 
= permute102()(
Tensor(name=None, shape=1, 77, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_0_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_0_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_0_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_0_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_0_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_0_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_0_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_0_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_1_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_1_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_1_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_1_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_1_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_1_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_1_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_1_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_2_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_2_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_2_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_2_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_2_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_2_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_2_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_2_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_3_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_3_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_3_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_3_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_3_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_3_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_3_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_3_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_4_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_4_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_4_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_4_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_4_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_4_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_4_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_4_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_5_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_5_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_5_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_5_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_5_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_5_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_5_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_5_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_6_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_6_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_6_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_6_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_6_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_6_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_6_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_6_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_7_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_7_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_7_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_7_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_7_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_7_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_7_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_7_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_8_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_8_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_8_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_8_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_8_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_8_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_8_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_8_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_9_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_9_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_9_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_9_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_9_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_9_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_9_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_9_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_10_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_10_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_10_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_10_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_10_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_10_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_10_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_10_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_11_ln_1_bias, shape=512))

(Tensor(name=None, shape=77, 1, 512)) 
= elementwise(FuncEnum.ADD)(
Tensor(name=None, shape=77, 1, 512), Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_attn_qkv_weight, shape=1536, 512))

(Tensor(name=None, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=None, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=None, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=None, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_11_attn_cu_length, shape=2))

(Tensor(name=None, shape=77, 512)) 
= reshape()(
Tensor(name=None, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=None, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=None, shape=77, 512),
Tensor(name=transformer_resblocks_11_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_11_attn_proj_bias, shape=512),
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=None, shape=77, 1, 512)) 
= reshape()(
Tensor(name=None, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=None, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_11_ln_2_bias, shape=512))

(Tensor(name=None, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_11_mlp_c_fc_bias, shape=2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.SIGMOID)(
Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 2048)) 
= elementwise(FuncEnum.MUL)(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=None, shape=77, 1, 2048))

(Tensor(name=None, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=None, shape=77, 1, 2048), Tensor(name=transformer_resblocks_11_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_11_mlp_c_proj_bias, shape=512))

(Tensor(name=None, shape=1, 77, 512)) 
= permute102()(
Tensor(name=None, shape=77, 1, 512))

(Tensor(name=output_0, shape=1, 77, 512)) 
= layernorm()(
Tensor(name=None, shape=1, 77, 512), Tensor(name=ln_final_weight, shape=512, data=(1024 bytes)), Tensor(name=ln_final_bias, shape=512, data=(1024 bytes)))
