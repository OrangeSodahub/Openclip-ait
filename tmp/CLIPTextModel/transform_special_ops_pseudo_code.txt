(Tensor(name=reshape_0_0, shape=77)) 
= reshape()(
Tensor(name=input, shape=1, 77), shape=[-1])

(Tensor(name=batch_gather_1_0, shape=77, 512)) 
= batch_gather()(
Tensor(name=token_embedding_weight, shape=49408, 512, data=(50593792 bytes)), Tensor(name=reshape_0_0, shape=77))

(IntVarTensor(1), IntVarTensor(77)) 
= size()(
Tensor(name=input, shape=1, 77))

(Tensor(name=reshape_3_0, shape=1, 77, 512)) 
= reshape()(
Tensor(name=batch_gather_1_0, shape=77, 512), shape=[1, 77, -1])

(Tensor(name=elementwise_4_0, shape=1, 77, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=reshape_3_0, shape=1, 77, 512), Tensor(name=positional_embedding, shape=77, 512, data=(78848 bytes)))

(Tensor(name=permute102_5_0, shape=77, 1, 512)) 
= permute102()(
Tensor(name=elementwise_4_0, shape=1, 77, 512))

(Tensor(name=layernorm_6_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=permute102_5_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_0_ln_1_bias, shape=512))

(Tensor(name=elementwise_7_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_6_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_8_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_7_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_9_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_8_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_10_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_9_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_0_attn_cu_length, shape=2))

(Tensor(name=reshape_11_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_10_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_12_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_11_0, shape=77, 512),
Tensor(name=transformer_resblocks_0_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_0_attn_proj_bias, shape=512),
Tensor(name=permute102_5_0, shape=77, 1, 512))

(Tensor(name=reshape_13_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_12_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_14_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_13_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_0_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_15_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_14_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_0_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_0_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_18_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_15_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_19_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_18_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_0_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_0_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_20_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_19_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_1_ln_1_bias, shape=512))

(Tensor(name=elementwise_21_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_20_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_22_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_21_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_23_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_22_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_24_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_23_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_1_attn_cu_length, shape=2))

(Tensor(name=reshape_25_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_24_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_26_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_25_0, shape=77, 512),
Tensor(name=transformer_resblocks_1_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_1_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_19_0, shape=77, 1, 512))

(Tensor(name=reshape_27_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_26_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_28_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_27_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_1_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_29_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_28_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_1_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_1_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_32_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_29_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_33_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_32_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_1_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_1_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_34_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_33_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_2_ln_1_bias, shape=512))

(Tensor(name=elementwise_35_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_34_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_36_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_35_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_37_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_36_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_38_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_37_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_2_attn_cu_length, shape=2))

(Tensor(name=reshape_39_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_38_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_40_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_39_0, shape=77, 512),
Tensor(name=transformer_resblocks_2_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_2_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_33_0, shape=77, 1, 512))

(Tensor(name=reshape_41_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_40_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_42_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_41_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_2_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_43_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_42_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_2_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_2_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_46_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_43_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_47_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_46_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_2_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_2_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_48_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_47_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_3_ln_1_bias, shape=512))

(Tensor(name=elementwise_49_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_48_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_50_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_49_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_51_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_50_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_52_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_51_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_3_attn_cu_length, shape=2))

(Tensor(name=reshape_53_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_52_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_54_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_53_0, shape=77, 512),
Tensor(name=transformer_resblocks_3_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_3_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_47_0, shape=77, 1, 512))

(Tensor(name=reshape_55_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_54_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_56_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_55_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_3_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_57_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_56_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_3_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_3_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_60_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_57_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_61_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_60_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_3_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_3_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_62_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_61_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_4_ln_1_bias, shape=512))

(Tensor(name=elementwise_63_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_62_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_64_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_63_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_65_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_64_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_66_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_65_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_4_attn_cu_length, shape=2))

(Tensor(name=reshape_67_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_66_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_68_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_67_0, shape=77, 512),
Tensor(name=transformer_resblocks_4_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_4_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_61_0, shape=77, 1, 512))

(Tensor(name=reshape_69_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_68_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_70_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_69_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_4_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_71_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_70_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_4_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_4_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_74_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_71_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_75_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_74_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_4_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_4_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_76_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_75_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_5_ln_1_bias, shape=512))

(Tensor(name=elementwise_77_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_76_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_78_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_77_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_79_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_78_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_80_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_79_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_5_attn_cu_length, shape=2))

(Tensor(name=reshape_81_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_80_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_82_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_81_0, shape=77, 512),
Tensor(name=transformer_resblocks_5_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_5_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_75_0, shape=77, 1, 512))

(Tensor(name=reshape_83_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_82_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_84_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_83_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_5_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_85_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_84_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_5_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_5_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_88_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_85_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_89_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_88_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_5_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_5_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_90_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_89_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_6_ln_1_bias, shape=512))

(Tensor(name=elementwise_91_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_90_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_92_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_91_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_93_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_92_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_94_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_93_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_6_attn_cu_length, shape=2))

(Tensor(name=reshape_95_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_94_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_96_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_95_0, shape=77, 512),
Tensor(name=transformer_resblocks_6_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_6_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_89_0, shape=77, 1, 512))

(Tensor(name=reshape_97_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_96_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_98_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_97_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_6_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_99_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_98_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_6_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_6_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_102_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_99_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_103_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_102_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_6_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_6_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_104_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_103_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_7_ln_1_bias, shape=512))

(Tensor(name=elementwise_105_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_104_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_106_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_105_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_107_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_106_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_108_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_107_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_7_attn_cu_length, shape=2))

(Tensor(name=reshape_109_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_108_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_110_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_109_0, shape=77, 512),
Tensor(name=transformer_resblocks_7_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_7_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_103_0, shape=77, 1, 512))

(Tensor(name=reshape_111_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_110_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_112_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_111_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_7_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_113_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_112_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_7_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_7_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_116_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_113_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_117_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_116_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_7_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_7_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_118_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_117_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_8_ln_1_bias, shape=512))

(Tensor(name=elementwise_119_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_118_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_120_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_119_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_121_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_120_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_122_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_121_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_8_attn_cu_length, shape=2))

(Tensor(name=reshape_123_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_122_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_124_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_123_0, shape=77, 512),
Tensor(name=transformer_resblocks_8_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_8_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_117_0, shape=77, 1, 512))

(Tensor(name=reshape_125_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_124_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_126_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_125_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_8_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_127_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_126_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_8_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_8_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_130_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_127_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_131_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_130_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_8_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_8_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_132_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_131_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_9_ln_1_bias, shape=512))

(Tensor(name=elementwise_133_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_132_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_134_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_133_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_135_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_134_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_136_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_135_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_9_attn_cu_length, shape=2))

(Tensor(name=reshape_137_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_136_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_138_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_137_0, shape=77, 512),
Tensor(name=transformer_resblocks_9_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_9_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_131_0, shape=77, 1, 512))

(Tensor(name=reshape_139_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_138_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_140_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_139_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_9_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_141_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_140_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_9_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_9_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_144_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_141_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_145_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_144_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_9_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_9_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_146_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_145_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_10_ln_1_bias, shape=512))

(Tensor(name=elementwise_147_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_146_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_148_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_147_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_149_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_148_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_150_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_149_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_10_attn_cu_length, shape=2))

(Tensor(name=reshape_151_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_150_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_152_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_151_0, shape=77, 512),
Tensor(name=transformer_resblocks_10_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_10_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_145_0, shape=77, 1, 512))

(Tensor(name=reshape_153_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_152_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_154_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_153_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_10_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_155_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_154_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_10_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_10_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_158_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_155_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_159_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_158_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_10_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_10_mlp_c_proj_bias, shape=512))

(Tensor(name=layernorm_160_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=gemm_rcr_bias_159_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_ln_1_weight, shape=512), Tensor(name=transformer_resblocks_11_ln_1_bias, shape=512))

(Tensor(name=elementwise_161_0, shape=77, 1, 512)) 
= fused_elementwise(FuncEnum.ADD)(
Tensor(name=layernorm_160_0, shape=77, 1, 512))

(Tensor(name=gemm_rcr_162_0, shape=77, 1, 1536)) 
= gemm_rcr()(
Tensor(name=elementwise_161_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_attn_qkv_weight, shape=1536, 512))

(Tensor(name=reshape_163_0, shape=77, 3, 8, 64)) 
= reshape()(
Tensor(name=gemm_rcr_162_0, shape=77, 1, 1536), shape=[77, 3, 8, 64])

(Tensor(name=flash_attention_164_0, shape=77, 8, 64)) 
= flash_attention()(
Tensor(name=reshape_163_0, shape=77, 3, 8, 64), Tensor(name=transformer_resblocks_11_attn_cu_length, shape=2))

(Tensor(name=reshape_165_0, shape=77, 512)) 
= reshape()(
Tensor(name=flash_attention_164_0, shape=77, 8, 64), shape=[77, -1])

(Tensor(name=gemm_rcr_bias_add_166_0, shape=77, 512)) 
= gemm_rcr_bias_add()(
Tensor(name=reshape_165_0, shape=77, 512),
Tensor(name=transformer_resblocks_11_attn_proj_weight, shape=512, 512),
Tensor(name=transformer_resblocks_11_attn_proj_bias, shape=512),
Tensor(name=gemm_rcr_bias_159_0, shape=77, 1, 512))

(Tensor(name=reshape_167_0, shape=77, 1, 512)) 
= reshape()(
Tensor(name=gemm_rcr_bias_add_166_0, shape=77, 512), shape=[77, 1, 512])

(Tensor(name=layernorm_168_0, shape=77, 1, 512)) 
= layernorm()(
Tensor(name=reshape_167_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_ln_2_weight, shape=512), Tensor(name=transformer_resblocks_11_ln_2_bias, shape=512))

(Tensor(name=gemm_rcr_bias_169_0, shape=77, 1, 2048)) 
= gemm_rcr_bias()(
Tensor(name=layernorm_168_0, shape=77, 1, 512), Tensor(name=transformer_resblocks_11_mlp_c_fc_weight, shape=2048, 512), Tensor(name=transformer_resblocks_11_mlp_c_fc_bias, shape=2048))

(Tensor(name=elementwise_172_0, shape=77, 1, 2048)) 
= fused_elementwise(FuncEnum.MUL, FuncEnum.SIGMOID, FuncEnum.MUL)(
Tensor(name=gemm_rcr_bias_169_0, shape=77, 1, 2048))

(Tensor(name=gemm_rcr_bias_173_0, shape=77, 1, 512)) 
= gemm_rcr_bias()(
Tensor(name=elementwise_172_0, shape=77, 1, 2048), Tensor(name=transformer_resblocks_11_mlp_c_proj_weight, shape=512, 2048), Tensor(name=transformer_resblocks_11_mlp_c_proj_bias, shape=512))

(Tensor(name=permute102_174_0, shape=1, 77, 512)) 
= permute102()(
Tensor(name=gemm_rcr_bias_173_0, shape=77, 1, 512))

(Tensor(name=output_0, shape=1, 77, 512)) 
= layernorm()(
Tensor(name=permute102_174_0, shape=1, 77, 512), Tensor(name=ln_final_weight, shape=512, data=(1024 bytes)), Tensor(name=ln_final_bias, shape=512, data=(1024 bytes)))
